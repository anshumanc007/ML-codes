{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nueralnetwork.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"UYz07iptcDSy","colab_type":"code","colab":{}},"cell_type":"code","source":["from google.colab import files"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8pqO-AmezqBu","colab_type":"code","colab":{}},"cell_type":"code","source":["files.upload()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6IOR4Bc7cQwn","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd;\n","import numpy as np;\n","data=pd.read_csv(\"clusterincluster.txt\",sep=\" \",header=None)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"coMj_5qhcrmE","colab_type":"code","colab":{}},"cell_type":"code","source":["X=data.iloc[ :, :-1].values\n","Y=data.iloc[:,2].values\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VLZsd9D0cymP","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, Y_train, Y_test= train_test_split(X,Y,test_size=0.2)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MUww0cbmdELd","colab_type":"code","colab":{}},"cell_type":"code","source":["#FEATURE_SCALING\n","from sklearn.preprocessing import StandardScaler\n","sc_X=StandardScaler()\n","X_train=sc_X.fit_transform(X_train)\n","X_test=sc_X.fit_transform(X_test)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eIbMvtmXdHHJ","colab_type":"code","colab":{}},"cell_type":"code","source":["#defining the sizes of layer\n","n_h=4; #number of hidden layer is four\n","n_inp=X.shape[1];\n","n_out=1;\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3kdOewx4ib-f","colab_type":"code","colab":{}},"cell_type":"code","source":["def sigmoid(z):\n","  k=1/(1+np.exp(-z));\n","  return k;"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ESh7Ws2FfcfB","colab_type":"code","colab":{}},"cell_type":"code","source":["#initialising the parameters of a NN\n","def initialisation(n_inp,n_h,n_out):\n","  W1=np.random.randn(n_h,n_inp)*0.01;\n","  b1=np.zeros((n_h,1));\n","  W2=np.random.randn(n_out,n_h)*0.01;\n","  b2=np.zeros((n_out,1));\n","  parameters={\"W1\":W1,\n","              \"b1\":b1,\n","              \"W2\":W2,\n","              \"b2\":b2}\n","  return parameters;"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6gCa_P_Og-2h","colab_type":"code","colab":{}},"cell_type":"code","source":["def forward_prop(X,parameters):\n","  W1=parameters['W1'];\n","  W2=parameters['W2'];\n","  b1=parameters['b1'];\n","  b2=parameters['b2'];\n","  #the activation function for the first function can be selected which suits the dataset in the best way.\n","  \n","  Z1=np.dot(W1,X)+b1;\n","  A1=np.tanh(Z1)\n","  #the activation function for the final layer should be a sigmoid in the case of a classification problem.\n","  Z2=np.dot(W2,A1)+b2;\n","  A2=sigmoid(Z2);\n","  cache={\"Z1\":Z1,\n","         \"A1\":A1,\n","         \"A2\":A2,\n","         \"Z2\":Z2}\n","  return A2,cache;"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yTCRrdJgi0g5","colab_type":"code","colab":{}},"cell_type":"code","source":["def compute_cost(A2,Y):\n","  m=Y.shape[0];\n","  cost=-1/m*(np.multiply(Y,np.log(A2))+np.multiply(1-Y,np.log(1-A2)));\n","  return cost;"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DHOoVmaIjfXQ","colab_type":"code","colab":{}},"cell_type":"code","source":["def backward_prop(parameters,cache,X,Y):\n","  W1 = parameters['W1'];\n","  W2 = parameters['W2'];\n","  b1 = parameters['b1'];\n","  b2 = parameters['b2']; \n","  A1 = cache['A1'];\n","  A2 = cache['A2'];\n","  Z1=  cache['Z1'];\n","  Z2=  cache['Z2'];\n","  m=X.shape[1];\n","  dZ2=A2-Y;\n","  dW2=1/m*np.dot(dZ2,A1.T);\n","  db2=1/m*np.sum(dZ2,axis=1,keepdims=True);\n","  #here it depends on the activation function of the hidden layer!\n","  dZ1=np.multiply(np.dot(W2.T,dZ2),(1-(A1)**2));\n","  dW1=1/m*np.dot(dZ1,X.T);\n","  db1=1/m*np.sum(dZ1,axis=1,keepdims=True);\n","  grads={\"dW2\":dW2,\n","         \"dW1\":dW1,\n","         \"db1\":db1,\n","         \"db2\":db2\n","         }\n","  return grads;"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RZk_iv3gl_T4","colab_type":"code","colab":{}},"cell_type":"code","source":["def optimise(X,Y,num_iteration,alpha):\n","    parameters = initialisation(n_inp, n_h, n_out);\n","    W1 = parameters['W1'];\n","    b1 = parameters['b1'];\n","    W2 = parameters['W2'];\n","    b2 = parameters['b2'];\n","    costs=[];\n","    for i in range(num_iteration):\n","      A2, cache = forward_prop(X, parameters);\n","      cost = compute_cost(A2, Y);\n","      costs.append(cost);\n","      grads = backward_prop(parameters, cache, X, Y);\n","      dW1=grads['dW1'];\n","      db1=grads['db1'];\n","      dW2=grads['dW2'];\n","      db2=grads['db2'];\n","      W1 =  W1-alpha * dW1;\n","      b1 =  b1-alpha * db1;\n","      W2 =  W2-alpha * dW2;\n","      b2 =  b2-alpha * db2;\n","      parameters={\"W1\": W1,\n","                \"b1\":b1,\n","                \"W2\":W2,\n","                \"b2\":b2,\n","               }\n","      \n","  \n","   \n","    return parameters;"],"execution_count":0,"outputs":[]},{"metadata":{"id":"snY6i4ljn7ES","colab_type":"code","colab":{}},"cell_type":"code","source":["def predict(X,parameters):\n","  A2,cache=forward_prop(X,parameters);\n","  P=np.round(A2);\n","  return P;"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dsrgrvQoo4kL","colab_type":"code","colab":{}},"cell_type":"code","source":["def model(X_train,Y_train,X_test,Y_test,num_iterations,alpha):\n","  parameters=optimise(X_train,Y_train,num_iterations,alpha);\n","  Y_P_train=predict(X_train,parameters);\n","  Y_P_test=predict(X_test,parameters);\n","  print(100 - np.mean(np.abs(Y_P_train - Y_train)) * 100);\n","  print((100 - np.mean(np.abs(Y_P_test - Y_test)) * 100));\n","  W1 = parameters['W1'];\n","  W2 = parameters['W2'];\n","  b1 = parameters['b1'];\n","  b2 = parameters['b2']; \n","  d = {  \"Y_prediction_test\": Y_P_test, \n","         \"Y_prediction_train\" : Y_P_train, \n","         \"W1\" : W1, \n","         \"b1\" : b1,\n","         \"W2\":  W2,\n","         \"b2\":  b2,\n","         \"learning_rate\" : alpha,\n","         \"num_iterations\": num_iterations};\n","  return d;\n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"qp86tRw8rHjY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"2e970d09-f694-4ec5-d3fd-2975abf66fb1","executionInfo":{"status":"ok","timestamp":1546906338506,"user_tz":-330,"elapsed":2586,"user":{"displayName":"anshuman choudhary","photoUrl":"https://lh4.googleusercontent.com/-bYyLbZbmzBs/AAAAAAAAAAI/AAAAAAAAAA0/Ee3Fwe60ql0/s64/photo.jpg","userId":"17214665107934152436"}}},"cell_type":"code","source":["d = model(X_train.T, Y_train.T, X_test.T ,Y_test.T, num_iterations = 1000, alpha=0.80)"],"execution_count":150,"outputs":[{"output_type":"stream","text":["100.0\n","100.0\n"],"name":"stdout"}]},{"metadata":{"id":"t0COl9TFyHCn","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}